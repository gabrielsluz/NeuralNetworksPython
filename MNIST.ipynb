{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from softmax_neural_network import *\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tests different modifications to a softmax output neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12de95780>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl30AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d91ad68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "image_index = 60# You may select anything up to 60,000\n",
    "print(y_train_orig[image_index]) \n",
    "plt.imshow(x_train_orig[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 10\n",
      "y_train shape = (10, 60000)\n",
      "y_test shape = (10, 10000)\n",
      "one_hot = [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] original label = 5\n",
      "one_hot = [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] original label = 2\n",
      "x_train shape = (784, 60000)\n",
      "x_test shape = (784, 10000)\n"
     ]
    }
   ],
   "source": [
    "#Basic setup\n",
    "def one_hotorize(x, num_labels):\n",
    "    #x must be of shape (1,m)\n",
    "    m = x.shape[1]\n",
    "    columns = np.arange(m)\n",
    "    one_indexes = x\n",
    "    one_hot = np.zeros((num_labels, m))\n",
    "    one_hot[one_indexes, columns] = 1\n",
    "    return one_hot\n",
    "    \n",
    "num_labels = 10\n",
    "print(\"Number of labels = \" + str(num_labels))\n",
    "\n",
    "#Reshaping the y arrays, to be an example each column and one hot vetors\n",
    "y_train_one = y_train_orig.reshape(y_train_orig.shape[0],1).T\n",
    "y_test_one = y_test_orig.reshape(y_test_orig.shape[0],1).T\n",
    "\n",
    "y_train = one_hotorize(y_train_one, num_labels)\n",
    "y_test = one_hotorize(y_test_one, num_labels)\n",
    "\n",
    "print(\"y_train shape = \" + str(y_train.shape))\n",
    "print(\"y_test shape = \" + str(y_test.shape))\n",
    "\n",
    "print(\"one_hot = \" + str(y_train[:,0]) + \" original label = \" + str(y_train_orig[0]))\n",
    "print(\"one_hot = \" + str(y_train[:,555]) + \" original label = \" + str(y_train_orig[555]))\n",
    "\n",
    "#Reshaping the x tensors to a matrix of the examples as each column\n",
    "x_train = x_train_orig.reshape(x_train_orig.shape[0],x_train_orig.shape[1] * x_train_orig.shape[2]) .T\n",
    "x_test = x_test_orig.reshape(x_test_orig.shape[0],x_test_orig.shape[1] * x_test_orig.shape[2]) .T\n",
    "print(\"x_train shape = \" + str(x_train.shape))\n",
    "print(\"x_test shape = \" + str(x_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "n_x = x_train.shape[0]\n",
    "layers = [n_x, num_labels]\n",
    "num_hidden_layers = len(layers) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeba/Desktop/DeepLearning/NeuralNetworksPython/activation_functions.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  x_exp = np.exp(x)\n",
      "/Users/zeba/Desktop/DeepLearning/NeuralNetworksPython/activation_functions.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return x_exp / np.sum(x_exp, axis = 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (60000,1) (10,784) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b0e79ab484f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_SNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rand\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/zeba/Desktop/DeepLearning/NeuralNetworksPython/softmax_neural_network.py\u001b[0m in \u001b[0;36mmodel_SNN\u001b[0;34m(X, Y, layers, learning_rate, num_iterations, print_cost, print_every, initialization, loaded_parameters)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mcosts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_cost_Softmax_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cost in iteration \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zeba/Desktop/DeepLearning/NeuralNetworksPython/softmax_neural_network.py\u001b[0m in \u001b[0;36mcompute_cost_Softmax_NN\u001b[0;34m(A, Y)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mloss_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Loss function with epsilon to avoid log(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (60000,1) (10,784) "
     ]
    }
   ],
   "source": [
    "parameters, costs = model_SNN(x_train, y_train, layers, learning_rate = 0.5, num_iterations = 1000, print_cost = True, print_every = 100, initialization = \"rand\", loaded_parameters = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
